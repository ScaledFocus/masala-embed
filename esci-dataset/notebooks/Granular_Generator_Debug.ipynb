{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granular Generator Debug Notebook\n",
    "\n",
    "**Deep dive into DSPy components for advanced tinkering and debugging.**\n",
    "\n",
    "This notebook exposes the full DSPy function code for modification, experimentation, and detailed debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import dspy\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Setup project paths\n",
    "project_root = os.environ.get(\"root_folder\")\n",
    "if project_root:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    sys.path.insert(0, os.path.join(project_root, \"esci-dataset\"))\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'MODEL': 'gpt-4o-mini',\n",
    "    'TEMPERATURE': 1.2,\n",
    "    'ESCI_LABEL': 'E'\n",
    "}\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"‚úÖ Setup complete. Model: {CONFIG['MODEL']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß DSPy Model Setup (TINKER HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dspy_model_debug(api_key: str, model: str = \"gpt-5-mini\", temperature: float = 0.7) -> None:\n",
    "    \"\"\"Setup DSPy with OpenAI model - FULL FUNCTION FOR TINKERING.\"\"\"\n",
    "    try:\n",
    "        # Check if it's a GPT-5 reasoning model with special requirements\n",
    "        if model.startswith(\"gpt-5\"):\n",
    "            print(\"üß† GPT-5 model detected - using special parameters\")\n",
    "            lm = dspy.LM(\n",
    "                model=f\"openai/{model}\",\n",
    "                api_key=api_key,\n",
    "                max_tokens=128000,  # GPT-5 requires max_tokens >= 16000\n",
    "                temperature=1.0,    # GPT-5 requires temperature=1.0\n",
    "                model_type='responses'  # GPT-5 requires model_type='responses'\n",
    "            )\n",
    "        else:\n",
    "            print(f\"üîß Standard model parameters for {model}\")\n",
    "            lm = dspy.LM(\n",
    "                model=f\"openai/{model}\",\n",
    "                api_key=api_key,\n",
    "                max_tokens=4000,\n",
    "                temperature=temperature\n",
    "            )\n",
    "\n",
    "        # Configure DSPy\n",
    "        dspy.settings.configure(lm=lm)\n",
    "        print(f\"‚úÖ DSPy configured: {model}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"DSPy LM initialization failed for model '{model}': {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        raise RuntimeError(error_msg) from e\n",
    "\n",
    "# Setup model\n",
    "setup_dspy_model_debug(OPENAI_API_KEY, CONFIG['MODEL'], CONFIG['TEMPERATURE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Query Generator Class (TINKER HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryGeneratorSignature(dspy.Signature):\n",
    "    \"\"\"DSPy signature for query generation task.\"\"\"\n",
    "    prompt_with_candidates = dspy.InputField(\n",
    "        desc=\"Complete prompt with food candidates and instructions\"\n",
    "    )\n",
    "    esci_label = dspy.InputField(\n",
    "        desc=\"ESCI label (E/S/C/I) to generate queries for\"\n",
    "    )\n",
    "    generated_queries = dspy.OutputField(\n",
    "        desc=\"JSON string containing generated queries following the specified format\"\n",
    "    )\n",
    "\n",
    "class QueryGeneratorDebug(dspy.Module):\n",
    "    \"\"\"DSPy module for generating food delivery queries - TINKER VERSION.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # EXPERIMENT HERE: Try different DSPy modules\n",
    "        # self.generate = dspy.Predict(QueryGeneratorSignature)\n",
    "        # self.generate = dspy.ReAct(QueryGeneratorSignature)\n",
    "        self.generate = dspy.ChainOfThought(QueryGeneratorSignature)\n",
    "\n",
    "    def forward(self, prompt_with_candidates: str, esci_label: str) -> str:\n",
    "        \"\"\"Generate queries using DSPy with detailed logging.\"\"\"\n",
    "        print(\"üöÄ API call starting...\")\n",
    "        print(f\"   Model: {CONFIG['MODEL']}\")\n",
    "        print(f\"   ESCI: {esci_label}\")\n",
    "        print(f\"   Prompt: {len(prompt_with_candidates)} chars\")\n",
    "\n",
    "        try:\n",
    "            result = self.generate(\n",
    "                prompt_with_candidates=prompt_with_candidates,\n",
    "                esci_label=esci_label\n",
    "            )\n",
    "            print(f\"   ‚úÖ Success: {len(result.generated_queries)} chars\")\n",
    "            return result.generated_queries\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed: {e}\")\n",
    "            raise\n",
    "\n",
    "# Initialize generator\n",
    "generator = QueryGeneratorDebug()\n",
    "print(\"‚úÖ QueryGeneratorDebug ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Parsing Function (TINKER HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_generated_output_debug(json_str: str):\n",
    "    \"\"\"Parse the generated JSON string - TINKER VERSION.\"\"\"\n",
    "    print(f\"üîÑ Parsing response ({len(json_str)} chars)\")\n",
    "\n",
    "    # Check for empty responses\n",
    "    if not json_str or json_str.strip() == \"\":\n",
    "        raise ValueError(f\"Empty response from API: '{json_str}'\")\n",
    "\n",
    "    # ADD CUSTOM JSON CLEANING HERE\n",
    "    # json_str = json_str.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "    # json_str = json_str.strip()\n",
    "\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        print(\"   ‚úÖ JSON parsed successfully\")\n",
    "\n",
    "        # Validation (ADD CUSTOM CHECKS HERE)\n",
    "        if isinstance(data, dict):\n",
    "            print(f\"   üìä Keys: {list(data.keys())}\")\n",
    "            if 'candidates' in data:\n",
    "                print(f\"   üçΩÔ∏è Candidates found: {len(data['candidates'])}\")\n",
    "\n",
    "        # Mock Pydantic structure for compatibility\n",
    "        class MockOutput:\n",
    "            def __init__(self, data):\n",
    "                self.data = data\n",
    "            def model_dump(self):\n",
    "                return self.data\n",
    "\n",
    "        return MockOutput(data)\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"   ‚ùå JSON decode error: {e}\")\n",
    "        print(f\"   üìù Response preview: {json_str[:200]}...\")\n",
    "        raise ValueError(f\"JSON decode error: {e}\") from e\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Parsing error: {e}\")\n",
    "        raise ValueError(f\"Parsing failed: {e}\") from e\n",
    "\n",
    "print(\"üîß Debug parsing function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample prompt for testing\n",
    "sample_prompt = \"\"\"\n",
    "Generate realistic food delivery queries for EXACT matches.\n",
    "\n",
    "Food candidates:\n",
    "1. Pizza (cheese, ham, olives)\n",
    "2. Noodle Soup (tofu, scallions, broth)\n",
    "\n",
    "Generate 2 queries per item in JSON format:\n",
    "{\n",
    "  \"candidates\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"name\": \"Pizza\",\n",
    "      \"queries\": [\n",
    "        {\"query\": \"pizza delivery\", \"dimensions\": {}},\n",
    "        {\"query\": \"cheese pizza near me\", \"dimensions\": {\"location\": \"near me\"}}\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üìù Sample prompt ready ({len(sample_prompt)} chars)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Test API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test API call\n",
    "try:\n",
    "    result_json = generator(sample_prompt, CONFIG['ESCI_LABEL'])\n",
    "    print(\"\\nüîç RAW RESPONSE:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(result_json)\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå API call failed: {e}\")\n",
    "    result_json = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Test Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the response\n",
    "if result_json:\n",
    "    try:\n",
    "        parsed = parse_generated_output_debug(result_json)\n",
    "        candidates = parsed.model_dump().get(\"candidates\", [])\n",
    "\n",
    "        print(\"\\nüéØ PARSED RESULTS:\")\n",
    "        for candidate in candidates:\n",
    "            name = candidate.get(\"name\", \"Unknown\")\n",
    "            queries = candidate.get(\"queries\", [])\n",
    "            print(f\"\\nüçΩÔ∏è {name}:\")\n",
    "            for i, q in enumerate(queries, 1):\n",
    "                query = q.get(\"query\", \"\")\n",
    "                dims = q.get(\"dimensions\", {})\n",
    "                print(f\"   {i}. '{query}'\")\n",
    "                if dims:\n",
    "                    print(f\"      Dimensions: {dims}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Parsing failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå No response to parse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Experimentation Notes\n",
    "\n",
    "**Things to try:**\n",
    "\n",
    "1. **Different DSPy modules**:\n",
    "   - `dspy.Predict(QueryGeneratorSignature)` - Simple prediction\n",
    "   - `dspy.ReAct(QueryGeneratorSignature)` - Reasoning and acting\n",
    "   - `dspy.ChainOfThought(QueryGeneratorSignature)` - Step-by-step reasoning\n",
    "\n",
    "2. **Custom prompt preprocessing**:\n",
    "   - Add prompt cleaning in `forward()` method\n",
    "   - Modify input field descriptions\n",
    "   - Add context or examples dynamically\n",
    "\n",
    "3. **Response post-processing**:\n",
    "   - JSON cleaning in parsing function\n",
    "   - Custom validation rules\n",
    "   - Response filtering or enhancement\n",
    "\n",
    "4. **Model parameters**:\n",
    "   - Adjust `max_tokens` for longer responses\n",
    "   - Experiment with `temperature` for creativity\n",
    "   - Try different models (GPT-4, GPT-5)\n",
    "\n",
    "**This notebook is your DSPy playground! üé™**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}