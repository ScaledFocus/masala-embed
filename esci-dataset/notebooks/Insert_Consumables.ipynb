{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ba3809",
   "metadata": {},
   "source": [
    "# Insert Consumables into Database\n",
    "\n",
    "This notebook provides a modular system for inserting food data from the MM-Food-100K dataset into the consumable table.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Source**: MM-Food-100K unique dishes dataset  \n",
    "- **Target**: PostgreSQL consumable table via Supabase\n",
    "- **Features**: Batch processing, error handling, data validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153682f6",
   "metadata": {},
   "source": [
    "## Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47d02012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n",
      "✓ Environment variables loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "import json\n",
    "import uuid\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n",
    "print(\"✓ Environment variables loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cd72246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 19,289 unique dishes\n",
      "✓ Dataset shape: (19289, 10)\n",
      "✓ Memory usage: 11.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Load the unique dishes dataset\n",
    "data_path = \"/Users/luvsuneja/Documents/repos/masala-embed/esci-dataset/data/mm-food-100k-unique-dishes.parquet\"\n",
    "df_unique_dishes = pd.read_parquet(data_path)\n",
    "\n",
    "print(f\"✓ Loaded {len(df_unique_dishes):,} unique dishes\")\n",
    "print(f\"✓ Dataset shape: {df_unique_dishes.shape}\")\n",
    "print(f\"✓ Memory usage: {df_unique_dishes.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ms9bl19iv",
   "metadata": {},
   "source": [
    "## Data Preparation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad30b0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Dropped 1 rows with missing required fields\n",
      "✓ Prepared 19288 records for insertion\n",
      "\\nSample prepared data:\n",
      "                                           image_url consumable_name  \\\n",
      "0  https://file.b18a.io/7843322356500104680_44354...   Fried Chicken   \n",
      "1  https://file.b18a.io/7833227147700100732_67487...             Pho   \n",
      "\n",
      "   consumable_type                             consumable_ingredients  \\\n",
      "0  Restaurant food                       [\"chicken\",\"breading\",\"oil\"]   \n",
      "1  Restaurant food  [\"noodles\",\"beef\",\"basil\",\"lime\",\"green onions...   \n",
      "\n",
      "                         consumable_portion_size  \\\n",
      "0                               [\"chicken:300g\"]   \n",
      "1  [\"noodles:200g\",\"beef:100g\",\"vegetables:50g\"]   \n",
      "\n",
      "                      consumable_nutritional_profile consumable_cooking_method  \n",
      "0  {'fat_g': 25.0, 'protein_g': 30.0, 'calories_k...                    Frying  \n",
      "1  {'fat_g': 15.0, 'protein_g': 25.0, 'calories_k...                    boiled  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jk/dyw0vdnx2jg9lyq8m01n8nfm0000gn/T/ipykernel_84025/1177156765.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['consumable_nutritional_profile'] = df['consumable_nutritional_profile'].apply(parse_json_field)\n",
      "/var/folders/jk/dyw0vdnx2jg9lyq8m01n8nfm0000gn/T/ipykernel_84025/1177156765.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[field] = df[field].astype(str).str.strip()\n",
      "/var/folders/jk/dyw0vdnx2jg9lyq8m01n8nfm0000gn/T/ipykernel_84025/1177156765.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[field] = df[field].replace('nan', None)\n",
      "/var/folders/jk/dyw0vdnx2jg9lyq8m01n8nfm0000gn/T/ipykernel_84025/1177156765.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[field] = df[field].astype(str).str.strip()\n",
      "/var/folders/jk/dyw0vdnx2jg9lyq8m01n8nfm0000gn/T/ipykernel_84025/1177156765.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[field] = df[field].replace('nan', None)\n",
      "/var/folders/jk/dyw0vdnx2jg9lyq8m01n8nfm0000gn/T/ipykernel_84025/1177156765.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[field] = df[field].astype(str).str.strip()\n",
      "/var/folders/jk/dyw0vdnx2jg9lyq8m01n8nfm0000gn/T/ipykernel_84025/1177156765.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[field] = df[field].replace('nan', None)\n"
     ]
    }
   ],
   "source": [
    "def prepare_consumable_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare DataFrame for insertion into consumable table.\n",
    "    \n",
    "    Args:\n",
    "        df: Source DataFrame with food data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame ready for database insertion\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original\n",
    "    df_prep = df.copy()\n",
    "    \n",
    "    # Map columns to database schema (no ID needed - auto-increment)\n",
    "    column_mapping = {\n",
    "        'image_url': 'image_url', \n",
    "        'dish_name': 'consumable_name',\n",
    "        'food_type': 'consumable_type',\n",
    "        'ingredients': 'consumable_ingredients',\n",
    "        'portion_size': 'consumable_portion_size',\n",
    "        'nutritional_profile': 'consumable_nutritional_profile',\n",
    "        'cooking_method': 'consumable_cooking_method'\n",
    "    }\n",
    "    \n",
    "    # Select and rename columns\n",
    "    df_prep = df_prep[column_mapping.keys()].rename(columns=column_mapping)\n",
    "    \n",
    "    # Clean and validate data\n",
    "    df_prep = clean_data(df_prep)\n",
    "    \n",
    "    print(f\"✓ Prepared {len(df_prep)} records for insertion\")\n",
    "    return df_prep\n",
    "\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean and validate data for database insertion.\"\"\"\n",
    "    \n",
    "    # Remove rows with missing required fields\n",
    "    required_fields = ['image_url', 'consumable_name']\n",
    "    initial_count = len(df)\n",
    "    df = df.dropna(subset=required_fields)\n",
    "    dropped_count = initial_count - len(df)\n",
    "    \n",
    "    if dropped_count > 0:\n",
    "        print(f\"⚠ Dropped {dropped_count} rows with missing required fields\")\n",
    "    \n",
    "    # Handle JSON fields - convert string representation to actual JSON\n",
    "    if 'consumable_nutritional_profile' in df.columns:\n",
    "        df['consumable_nutritional_profile'] = df['consumable_nutritional_profile'].apply(parse_json_field)\n",
    "    \n",
    "    # Clean text fields\n",
    "    text_fields = ['consumable_name', 'consumable_type', 'consumable_cooking_method']\n",
    "    for field in text_fields:\n",
    "        if field in df.columns:\n",
    "            df[field] = df[field].astype(str).str.strip()\n",
    "            df[field] = df[field].replace('nan', None)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def parse_json_field(value) -> Dict[str, Any]:\n",
    "    \"\"\"Parse JSON field, handling string representations.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    \n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            return json.loads(value)\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    \n",
    "    return value\n",
    "\n",
    "# Test the preparation function\n",
    "df_prepared = prepare_consumable_data(df_unique_dishes)\n",
    "print(\"\\\\nSample prepared data:\")\n",
    "print(df_prepared.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ee372b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Database Connection Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "vxv26557db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connected to database. Consumable table has 1 records\n"
     ]
    }
   ],
   "source": [
    "def get_db_connection():\n",
    "    \"\"\"Create database connection using environment variables.\"\"\"\n",
    "    try:\n",
    "        connection = psycopg2.connect(\n",
    "            user=os.getenv(\"user\"),\n",
    "            password=os.getenv(\"password\"),\n",
    "            host=os.getenv(\"host\"),\n",
    "            port=os.getenv(\"port\"),\n",
    "            dbname=os.getenv(\"dbname\")\n",
    "        )\n",
    "        return connection\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to connect to database: {e}\")\n",
    "        raise\n",
    "\n",
    "def test_connection():\n",
    "    \"\"\"Test database connection and basic operations.\"\"\"\n",
    "    try:\n",
    "        with get_db_connection() as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                # Test basic query\n",
    "                cursor.execute(\"SELECT NOW();\")\n",
    "                result = cursor.fetchone()\n",
    "                \n",
    "                # Check if consumable table exists\n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT EXISTS (\n",
    "                        SELECT FROM information_schema.tables \n",
    "                        WHERE table_name = 'consumable'\n",
    "                    );\n",
    "                \"\"\")\n",
    "                table_exists = cursor.fetchone()[0]\n",
    "                \n",
    "                if table_exists:\n",
    "                    # Get current record count\n",
    "                    cursor.execute(\"SELECT COUNT(*) FROM consumable;\")\n",
    "                    count = cursor.fetchone()[0]\n",
    "                    print(f\"✓ Connected to database. Consumable table has {count:,} records\")\n",
    "                else:\n",
    "                    print(\"⚠ Consumable table does not exist\")\n",
    "                \n",
    "                return table_exists\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Connection test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Test the connection\n",
    "connection_ok = test_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6be4e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_url                         https://file.b18a.io/7843322356500104680_44354...\n",
       "consumable_name                                                       Fried Chicken\n",
       "consumable_type                                                     Restaurant food\n",
       "consumable_ingredients                                 [\"chicken\",\"breading\",\"oil\"]\n",
       "consumable_portion_size                                            [\"chicken:300g\"]\n",
       "consumable_nutritional_profile    {'fat_g': 25.0, 'protein_g': 30.0, 'calories_k...\n",
       "consumable_cooking_method                                                    Frying\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepared.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5t5lpkjsc5",
   "metadata": {},
   "source": [
    "## Insertion Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62rnt21911v",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully inserted record\n",
      "✓ Record name: Fried Chicken\n",
      "✓ Total records in database: 2\n"
     ]
    }
   ],
   "source": [
    "# Simple single record insertion test\n",
    "def insert_single_record():\n",
    "    \"\"\"Insert a single test record to verify the schema works.\"\"\"\n",
    "    if not connection_ok:\n",
    "        raise Exception(\"Database connection not available\")\n",
    "    \n",
    "    # Get first record from prepared data\n",
    "    test_record = df_prepared.iloc[0]\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    INSERT INTO consumable (\n",
    "        image_url, consumable_name, consumable_type, \n",
    "        consumable_ingredients, consumable_portion_size, \n",
    "        consumable_nutritional_profile, consumable_cooking_method\n",
    "    ) VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with get_db_connection() as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                # Prepare data\n",
    "                nutrition = test_record['consumable_nutritional_profile']\n",
    "                if nutrition is not None:\n",
    "                    nutrition = json.dumps(nutrition) if not isinstance(nutrition, str) else nutrition\n",
    "                \n",
    "                # Execute insert\n",
    "                cursor.execute(sql, (\n",
    "                    test_record['image_url'],\n",
    "                    test_record['consumable_name'],\n",
    "                    test_record['consumable_type'],\n",
    "                    test_record['consumable_ingredients'],\n",
    "                    test_record['consumable_portion_size'],\n",
    "                    nutrition,\n",
    "                    test_record['consumable_cooking_method']\n",
    "                ))\n",
    "                \n",
    "                conn.commit()\n",
    "                print(f\"✓ Successfully inserted record\")\n",
    "                print(f\"✓ Record name: {test_record['consumable_name']}\")\n",
    "                \n",
    "                # Verify insertion\n",
    "                cursor.execute(\"SELECT COUNT(*) FROM consumable\")\n",
    "                count = cursor.fetchone()[0]\n",
    "                print(f\"✓ Total records in database: {count}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to insert record: {e}\")\n",
    "        raise\n",
    "\n",
    "# Test single record insertion\n",
    "insert_single_record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75ee9433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of 3 records to be inserted:\n",
      "==================================================\n",
      "1. Fried Chicken (Restaurant food)\n",
      "   Cooking: Frying\n",
      "2. Pho (Restaurant food)\n",
      "   Cooking: boiled\n",
      "3. Pan-fried Dumplings (Restaurant food)\n",
      "   Cooking: Pan-frying\n"
     ]
    }
   ],
   "source": [
    "# Batch insertion module\n",
    "def insert_consumables_batch(df: pd.DataFrame, batch_size: int = 1000) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Insert consumables data in batches with progress tracking.\n",
    "    \n",
    "    Args:\n",
    "        df: Prepared DataFrame with consumable data\n",
    "        batch_size: Number of records per batch\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with insertion statistics\n",
    "    \"\"\"\n",
    "    if not connection_ok:\n",
    "        raise Exception(\"Database connection not available\")\n",
    "    \n",
    "    # Prepare SQL statement (no ID column - auto-increment)\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO consumable (\n",
    "        image_url, consumable_name, consumable_type, \n",
    "        consumable_ingredients, consumable_portion_size, \n",
    "        consumable_nutritional_profile, consumable_cooking_method\n",
    "    ) VALUES %s\n",
    "    \"\"\"\n",
    "    \n",
    "    stats = {\n",
    "        'total_records': len(df),\n",
    "        'successful_batches': 0,\n",
    "        'failed_batches': 0,\n",
    "        'total_inserted': 0,\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    total_batches = (len(df) + batch_size - 1) // batch_size\n",
    "    \n",
    "    with get_db_connection() as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            # Process data in batches with progress bar\n",
    "            pbar = tqdm(total=len(df), desc=\"Inserting records\", unit=\"records\")\n",
    "            \n",
    "            for i in range(0, len(df), batch_size):\n",
    "                batch_df = df.iloc[i:i+batch_size]\n",
    "                \n",
    "                try:\n",
    "                    # Prepare batch data (no ID - auto-increment)\n",
    "                    batch_data = []\n",
    "                    for _, row in batch_df.iterrows():\n",
    "                        # Convert nutritional profile to JSON string for PostgreSQL\n",
    "                        nutrition = row['consumable_nutritional_profile']\n",
    "                        if nutrition is not None:\n",
    "                            nutrition = json.dumps(nutrition) if not isinstance(nutrition, str) else nutrition\n",
    "                        \n",
    "                        batch_data.append((\n",
    "                            row['image_url'],\n",
    "                            row['consumable_name'],\n",
    "                            row['consumable_type'],\n",
    "                            row['consumable_ingredients'],\n",
    "                            row['consumable_portion_size'],\n",
    "                            nutrition,\n",
    "                            row['consumable_cooking_method']\n",
    "                        ))\n",
    "                    \n",
    "                    # Execute batch insert\n",
    "                    from psycopg2.extras import execute_values\n",
    "                    execute_values(cursor, sql, batch_data, template=None, page_size=batch_size)\n",
    "                    \n",
    "                    stats['successful_batches'] += 1\n",
    "                    stats['total_inserted'] += len(batch_data)\n",
    "                    \n",
    "                    pbar.update(len(batch_data))\n",
    "                \n",
    "                except Exception as e:\n",
    "                    stats['failed_batches'] += 1\n",
    "                    stats['errors'].append(f\"Batch failed: {str(e)}\")\n",
    "                    pbar.update(len(batch_data))\n",
    "                    # Continue with next batch instead of breaking\n",
    "                    continue\n",
    "            \n",
    "            pbar.close()\n",
    "            \n",
    "            # Commit all changes\n",
    "            conn.commit()\n",
    "            print(f\"✓ Insertion completed: {stats['total_inserted']:,}/{stats['total_records']:,} records\")\n",
    "            if stats['failed_batches'] > 0:\n",
    "                print(f\"⚠ {stats['failed_batches']} batches failed\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Function to preview what will be inserted\n",
    "def preview_insertion(df: pd.DataFrame, num_rows: int = 3):\n",
    "    \"\"\"Preview the data that will be inserted.\"\"\"\n",
    "    print(f\"Preview of {num_rows} records to be inserted:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, (_, row) in enumerate(df.head(num_rows).iterrows()):\n",
    "        print(f\"{i+1}. {row['consumable_name']} ({row['consumable_type']})\")\n",
    "        if row['consumable_cooking_method']:\n",
    "            print(f\"   Cooking: {row['consumable_cooking_method']}\")\n",
    "\n",
    "# Preview the prepared data\n",
    "preview_insertion(df_prepared, num_rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87zbgjxc43g",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to insert 19,287 records in batches...\n",
      "This may take several minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting records: 100%|██████████| 19287/19287 [00:04<00:00, 4337.09records/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Insertion completed: 19,287/19,287 records\n",
      "\n",
      "==================================================\n",
      "FINAL INSERTION STATISTICS\n",
      "==================================================\n",
      "total_records: 19287\n",
      "successful_batches: 39\n",
      "failed_batches: 0\n",
      "total_inserted: 19287\n",
      "errors: []\n",
      "\n",
      "✓ Final database count: 19,287 records\n"
     ]
    }
   ],
   "source": [
    "# Execute batch insertion\n",
    "# Run this to insert all remaining records (skip first one already inserted)\n",
    "df_to_insert = df_prepared.iloc[1:]  # Skip first record already inserted\n",
    "\n",
    "print(f\"About to insert {len(df_to_insert):,} records in batches...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "# Execute the batch insertion\n",
    "insertion_stats = insert_consumables_batch(df_to_insert, batch_size=500)\n",
    "\n",
    "# Display final statistics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL INSERTION STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "for key, value in insertion_stats.items():\n",
    "    if key == 'errors' and value:\n",
    "        print(f\"{key}: {len(value)} errors\")\n",
    "        for error in value[:5]:  # Show first 5 errors\n",
    "            print(f\"  - {error}\")\n",
    "        if len(value) > 5:\n",
    "            print(f\"  ... and {len(value) - 5} more errors\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Final verification\n",
    "if connection_ok:\n",
    "    with get_db_connection() as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM consumable\")\n",
    "            final_count = cursor.fetchone()[0]\n",
    "            print(f\"\\n✓ Final database count: {final_count:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0a520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masala-embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
