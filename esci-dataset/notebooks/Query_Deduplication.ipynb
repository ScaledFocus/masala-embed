{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Analysis\n",
    "\n",
    "Analysis of queries in the database to understand distribution and uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root folder: /Users/luvsuneja/Documents/repos/masala-embed/esci-dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "root_folder = os.environ.get(\"root_folder\")\n",
    "print(f\"Root folder: {root_folder}\")\n",
    "sys.path.append(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database.utils.db_utils import get_db_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jk/dyw0vdnx2jg9lyq8m01n8nfm0000gn/T/ipykernel_80367/1680117440.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  query_df = pd.read_sql(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records loaded: 4957\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query_content</th>\n",
       "      <th>query_filters</th>\n",
       "      <th>data_gen_hash</th>\n",
       "      <th>mlflow_run_id</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4709</td>\n",
       "      <td>Middle Eastern vegan friendly</td>\n",
       "      <td>None</td>\n",
       "      <td>5577177</td>\n",
       "      <td>aefc21fcce0440a28943f874c04dd37d</td>\n",
       "      <td>2025-09-24 18:16:35.174157+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4708</td>\n",
       "      <td>Middle Eastern sharing plates</td>\n",
       "      <td>None</td>\n",
       "      <td>5577177</td>\n",
       "      <td>aefc21fcce0440a28943f874c04dd37d</td>\n",
       "      <td>2025-09-24 18:16:35.174157+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4707</td>\n",
       "      <td>Korean food near me</td>\n",
       "      <td>None</td>\n",
       "      <td>5577177</td>\n",
       "      <td>aefc21fcce0440a28943f874c04dd37d</td>\n",
       "      <td>2025-09-24 18:16:35.174157+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5311</td>\n",
       "      <td>wholesome family dinner</td>\n",
       "      <td>None</td>\n",
       "      <td>5577177</td>\n",
       "      <td>aefc21fcce0440a28943f874c04dd37d</td>\n",
       "      <td>2025-09-24 18:16:35.174157+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5310</td>\n",
       "      <td>white-tablecloth vibes at home</td>\n",
       "      <td>None</td>\n",
       "      <td>5577177</td>\n",
       "      <td>aefc21fcce0440a28943f874c04dd37d</td>\n",
       "      <td>2025-09-24 18:16:35.174157+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                   query_content query_filters data_gen_hash  \\\n",
       "0  4709   Middle Eastern vegan friendly          None       5577177   \n",
       "1  4708   Middle Eastern sharing plates          None       5577177   \n",
       "2  4707             Korean food near me          None       5577177   \n",
       "3  5311         wholesome family dinner          None       5577177   \n",
       "4  5310  white-tablecloth vibes at home          None       5577177   \n",
       "\n",
       "                      mlflow_run_id                       created_at  \n",
       "0  aefc21fcce0440a28943f874c04dd37d 2025-09-24 18:16:35.174157+00:00  \n",
       "1  aefc21fcce0440a28943f874c04dd37d 2025-09-24 18:16:35.174157+00:00  \n",
       "2  aefc21fcce0440a28943f874c04dd37d 2025-09-24 18:16:35.174157+00:00  \n",
       "3  aefc21fcce0440a28943f874c04dd37d 2025-09-24 18:16:35.174157+00:00  \n",
       "4  aefc21fcce0440a28943f874c04dd37d 2025-09-24 18:16:35.174157+00:00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all queries from the query table\n",
    "with get_db_connection() as conn:\n",
    "    query_df = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            id,\n",
    "            query_content,\n",
    "            query_filters,\n",
    "            data_gen_hash,\n",
    "            mlflow_run_id,\n",
    "            created_at\n",
    "        FROM query\n",
    "        ORDER BY created_at DESC\n",
    "    \"\"\",\n",
    "        conn,\n",
    "    )\n",
    "\n",
    "print(f\"Total records loaded: {len(query_df)}\")\n",
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Query Analysis Summary\n",
      "========================\n",
      "Total records: 4,957\n",
      "Unique queries: 4,932\n",
      "Duplicate rate: 0.50%\n"
     ]
    }
   ],
   "source": [
    "# Get total records and unique queries\n",
    "total_records = len(query_df)\n",
    "unique_queries = query_df[\"query_content\"].nunique()\n",
    "\n",
    "print(f\"üìä Query Analysis Summary\")\n",
    "print(f\"========================\")\n",
    "print(f\"Total records: {total_records:,}\")\n",
    "print(f\"Unique queries: {unique_queries:,}\")\n",
    "print(\n",
    "    f\"Duplicate rate: {((total_records - unique_queries) / total_records * 100):.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(25)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts for query content\n",
    "query_value_counts = query_df[\"query_content\"].value_counts()\n",
    "(query_value_counts > 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Query Frequency Distribution:\n",
      "===============================\n",
      "\n",
      "4907 queries appear  1 time(s)\n",
      "  25 queries appear  2 time(s)\n"
     ]
    }
   ],
   "source": [
    "# Distribution of query frequencies\n",
    "frequency_distribution = query_value_counts.value_counts().sort_index()\n",
    "\n",
    "print(f\"\\nüìä Query Frequency Distribution:\")\n",
    "print(f\"===============================\\n\")\n",
    "for frequency, count in frequency_distribution.items():\n",
    "    print(f\"{count:4d} queries appear {frequency:2d} time(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ Analysis by MLflow Run:\n",
      "=========================\n",
      "\n",
      "                                  total_records  unique_queries  \\\n",
      "mlflow_run_id                                                     \n",
      "0c611a39b1844107b10d4f7ac9282770           2772            2772   \n",
      "3802814759d244af89aae038575f0202           1573            1573   \n",
      "aefc21fcce0440a28943f874c04dd37d            612             612   \n",
      "\n",
      "                                                    first_created  \\\n",
      "mlflow_run_id                                                       \n",
      "0c611a39b1844107b10d4f7ac9282770 2025-09-24 17:36:29.503553+00:00   \n",
      "3802814759d244af89aae038575f0202 2025-09-24 17:29:47.669335+00:00   \n",
      "aefc21fcce0440a28943f874c04dd37d 2025-09-24 18:16:35.174157+00:00   \n",
      "\n",
      "                                                     last_created  \\\n",
      "mlflow_run_id                                                       \n",
      "0c611a39b1844107b10d4f7ac9282770 2025-09-24 17:36:29.503553+00:00   \n",
      "3802814759d244af89aae038575f0202 2025-09-24 17:29:47.669335+00:00   \n",
      "aefc21fcce0440a28943f874c04dd37d 2025-09-24 18:16:35.174157+00:00   \n",
      "\n",
      "                                  duplicate_rate  \n",
      "mlflow_run_id                                     \n",
      "0c611a39b1844107b10d4f7ac9282770             0.0  \n",
      "3802814759d244af89aae038575f0202             0.0  \n",
      "aefc21fcce0440a28943f874c04dd37d             0.0  \n"
     ]
    }
   ],
   "source": [
    "# Analysis by MLflow run\n",
    "mlflow_analysis = (\n",
    "    query_df.groupby(\"mlflow_run_id\")\n",
    "    .agg({\"id\": \"count\", \"query_content\": \"nunique\", \"created_at\": [\"min\", \"max\"]})\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "mlflow_analysis.columns = [\n",
    "    \"total_records\",\n",
    "    \"unique_queries\",\n",
    "    \"first_created\",\n",
    "    \"last_created\",\n",
    "]\n",
    "mlflow_analysis[\"duplicate_rate\"] = (\n",
    "    (mlflow_analysis[\"total_records\"] - mlflow_analysis[\"unique_queries\"])\n",
    "    / mlflow_analysis[\"total_records\"]\n",
    "    * 100\n",
    ").round(2)\n",
    "\n",
    "print(f\"\\nüèÉ Analysis by MLflow Run:\")\n",
    "print(f\"=========================\\n\")\n",
    "print(mlflow_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Duplicate Queries Analysis:\n",
      "=============================\n",
      "Queries with duplicates: 25\n",
      "Total duplicate records: 25\n",
      "\n",
      "üîç First 5 Duplicate Queries:\n",
      "==============================\n",
      "\n",
      "Query: beef soup\n",
      "Count: 2 | Keep ID: 425 | All IDs: [2050, 425]\n",
      "\n",
      "Query: breakfast platter\n",
      "Count: 2 | Keep ID: 462 | All IDs: [2131, 462]\n",
      "\n",
      "Query: corn soup\n",
      "Count: 2 | Keep ID: 642 | All IDs: [2499, 642]\n",
      "\n",
      "Query: cream filled cookies\n",
      "Count: 2 | Keep ID: 653 | All IDs: [2520, 653]\n",
      "\n",
      "Query: egg rice bowl\n",
      "Count: 2 | Keep ID: 719 | All IDs: [2642, 719]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_content</th>\n",
       "      <th>count</th>\n",
       "      <th>first_id</th>\n",
       "      <th>all_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>beef soup</td>\n",
       "      <td>2</td>\n",
       "      <td>425</td>\n",
       "      <td>[2050, 425]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>breakfast platter</td>\n",
       "      <td>2</td>\n",
       "      <td>462</td>\n",
       "      <td>[2131, 462]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>corn soup</td>\n",
       "      <td>2</td>\n",
       "      <td>642</td>\n",
       "      <td>[2499, 642]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>cream filled cookies</td>\n",
       "      <td>2</td>\n",
       "      <td>653</td>\n",
       "      <td>[2520, 653]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>egg rice bowl</td>\n",
       "      <td>2</td>\n",
       "      <td>719</td>\n",
       "      <td>[2642, 719]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>fish with vegetables</td>\n",
       "      <td>2</td>\n",
       "      <td>753</td>\n",
       "      <td>[2705, 753]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>fruit platter</td>\n",
       "      <td>2</td>\n",
       "      <td>821</td>\n",
       "      <td>[2842, 821]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>fruit salad</td>\n",
       "      <td>2</td>\n",
       "      <td>822</td>\n",
       "      <td>[2845, 822]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>grilled chicken salad</td>\n",
       "      <td>2</td>\n",
       "      <td>858</td>\n",
       "      <td>[2914, 858]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>grilled salmon with vegetables</td>\n",
       "      <td>2</td>\n",
       "      <td>877</td>\n",
       "      <td>[2946, 877]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>hainanese chicken</td>\n",
       "      <td>2</td>\n",
       "      <td>891</td>\n",
       "      <td>[2969, 891]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>high protein dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>3112</td>\n",
       "      <td>[4976, 3112]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>italian seafood pasta under $20</td>\n",
       "      <td>2</td>\n",
       "      <td>1036</td>\n",
       "      <td>[3198, 1036]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>latte</td>\n",
       "      <td>2</td>\n",
       "      <td>1116</td>\n",
       "      <td>[3327, 1116]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>mixed meat skewers</td>\n",
       "      <td>2</td>\n",
       "      <td>1264</td>\n",
       "      <td>[3554, 1264]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>noodles with dumplings</td>\n",
       "      <td>2</td>\n",
       "      <td>1320</td>\n",
       "      <td>[3651, 1320]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>pescetarian fish main course</td>\n",
       "      <td>2</td>\n",
       "      <td>1378</td>\n",
       "      <td>[3774, 1378]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>seafood dumplings</td>\n",
       "      <td>2</td>\n",
       "      <td>1555</td>\n",
       "      <td>[4024, 1555]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>seafood hot pot</td>\n",
       "      <td>2</td>\n",
       "      <td>1557</td>\n",
       "      <td>[4025, 1557]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>seafood stew</td>\n",
       "      <td>2</td>\n",
       "      <td>1569</td>\n",
       "      <td>[4048, 1569]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3817</th>\n",
       "      <td>shabu shabu</td>\n",
       "      <td>2</td>\n",
       "      <td>1576</td>\n",
       "      <td>[4062, 1576]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>snack mix</td>\n",
       "      <td>2</td>\n",
       "      <td>1613</td>\n",
       "      <td>[4132, 1613]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4344</th>\n",
       "      <td>sushi bowl</td>\n",
       "      <td>2</td>\n",
       "      <td>1748</td>\n",
       "      <td>[4355, 1748]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>unagi don</td>\n",
       "      <td>2</td>\n",
       "      <td>1821</td>\n",
       "      <td>[4483, 1821]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>vegetable hot pot</td>\n",
       "      <td>2</td>\n",
       "      <td>1883</td>\n",
       "      <td>[4604, 1883]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        query_content  count  first_id       all_ids\n",
       "227                         beef soup      2       425   [2050, 425]\n",
       "360                 breakfast platter      2       462   [2131, 462]\n",
       "978                         corn soup      2       642   [2499, 642]\n",
       "1013             cream filled cookies      2       653   [2520, 653]\n",
       "1242                    egg rice bowl      2       719   [2642, 719]\n",
       "1378             fish with vegetables      2       753   [2705, 753]\n",
       "1597                    fruit platter      2       821   [2842, 821]\n",
       "1600                      fruit salad      2       822   [2845, 822]\n",
       "1721            grilled chicken salad      2       858   [2914, 858]\n",
       "1771   grilled salmon with vegetables      2       877   [2946, 877]\n",
       "1812                hainanese chicken      2       891   [2969, 891]\n",
       "2061              high protein dinner      2      3112  [4976, 3112]\n",
       "2241  italian seafood pasta under $20      2      1036  [3198, 1036]\n",
       "2481                            latte      2      1116  [3327, 1116]\n",
       "2903               mixed meat skewers      2      1264  [3554, 1264]\n",
       "3068           noodles with dumplings      2      1320  [3651, 1320]\n",
       "3272     pescetarian fish main course      2      1378  [3774, 1378]\n",
       "3759                seafood dumplings      2      1555  [4024, 1555]\n",
       "3761                  seafood hot pot      2      1557  [4025, 1557]\n",
       "3796                     seafood stew      2      1569  [4048, 1569]\n",
       "3817                      shabu shabu      2      1576  [4062, 1576]\n",
       "3934                        snack mix      2      1613  [4132, 1613]\n",
       "4344                       sushi bowl      2      1748  [4355, 1748]\n",
       "4569                        unagi don      2      1821  [4483, 1821]\n",
       "4770                vegetable hot pot      2      1883  [4604, 1883]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify duplicate queries with their IDs\n",
    "duplicate_queries = (\n",
    "    query_df.groupby(\"query_content\").agg({\"id\": [\"count\", \"min\", list]}).reset_index()\n",
    ")\n",
    "\n",
    "# Flatten column names\n",
    "duplicate_queries.columns = [\"query_content\", \"count\", \"first_id\", \"all_ids\"]\n",
    "\n",
    "# Filter only duplicates (count > 1)\n",
    "duplicates_only = duplicate_queries[duplicate_queries[\"count\"] > 1].copy()\n",
    "\n",
    "print(f\"üìã Duplicate Queries Analysis:\")\n",
    "print(f\"=============================\")\n",
    "print(f\"Queries with duplicates: {len(duplicates_only)}\")\n",
    "print(\n",
    "    f\"Total duplicate records: {duplicates_only['count'].sum() - len(duplicates_only)}\"\n",
    ")\n",
    "\n",
    "# Show first few duplicates\n",
    "print(f\"\\nüîç First 5 Duplicate Queries:\")\n",
    "print(f\"==============================\")\n",
    "for idx, row in duplicates_only.head().iterrows():\n",
    "    print(\n",
    "        f\"\\nQuery: {row['query_content'][:80]}{'...' if len(row['query_content']) > 80 else ''}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Count: {row['count']} | Keep ID: {row['first_id']} | All IDs: {row['all_ids']}\"\n",
    "    )\n",
    "\n",
    "duplicates_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Updating example table to reassign duplicate query_ids...\n",
      "Created mapping for 25 duplicate query IDs\n"
     ]
    }
   ],
   "source": [
    "# Update example table to reassign duplicate query_ids to first instance\n",
    "print(\"üîÑ Updating example table to reassign duplicate query_ids...\")\n",
    "\n",
    "# Create mapping of duplicate IDs to first ID\n",
    "id_mapping = {}\n",
    "for _, row in duplicates_only.iterrows():\n",
    "    first_id = row[\"first_id\"]\n",
    "    all_ids = row[\"all_ids\"]\n",
    "    # Map all duplicate IDs to the first ID\n",
    "    for query_id in all_ids:\n",
    "        if query_id != first_id:  # Don't map the first ID to itself\n",
    "            id_mapping[query_id] = first_id\n",
    "\n",
    "print(f\"Created mapping for {len(id_mapping)} duplicate query IDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2050: 425,\n",
       " 2131: 462,\n",
       " 2499: 642,\n",
       " 2520: 653,\n",
       " 2642: 719,\n",
       " 2705: 753,\n",
       " 2842: 821,\n",
       " 2845: 822,\n",
       " 2914: 858,\n",
       " 2946: 877,\n",
       " 2969: 891,\n",
       " 4976: 3112,\n",
       " 3198: 1036,\n",
       " 3327: 1116,\n",
       " 3554: 1264,\n",
       " 3651: 1320,\n",
       " 3774: 1378,\n",
       " 4024: 1555,\n",
       " 4025: 1557,\n",
       " 4048: 1569,\n",
       " 4062: 1576,\n",
       " 4132: 1613,\n",
       " 4355: 1748,\n",
       " 4483: 1821,\n",
       " 4604: 1883}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 1 examples: query_id 2050 ‚Üí 425\n",
      "Updated 1 examples: query_id 2131 ‚Üí 462\n",
      "Updated 1 examples: query_id 2499 ‚Üí 642\n",
      "Updated 1 examples: query_id 2520 ‚Üí 653\n",
      "Updated 1 examples: query_id 2642 ‚Üí 719\n",
      "Updated 1 examples: query_id 2705 ‚Üí 753\n",
      "Updated 1 examples: query_id 2842 ‚Üí 821\n",
      "Updated 1 examples: query_id 2845 ‚Üí 822\n",
      "Updated 1 examples: query_id 2914 ‚Üí 858\n",
      "Updated 1 examples: query_id 2946 ‚Üí 877\n",
      "Updated 1 examples: query_id 2969 ‚Üí 891\n",
      "Updated 2 examples: query_id 4976 ‚Üí 3112\n",
      "Updated 1 examples: query_id 3198 ‚Üí 1036\n",
      "Updated 1 examples: query_id 3327 ‚Üí 1116\n",
      "Updated 1 examples: query_id 3554 ‚Üí 1264\n",
      "Updated 1 examples: query_id 3651 ‚Üí 1320\n",
      "Updated 1 examples: query_id 3774 ‚Üí 1378\n",
      "Updated 1 examples: query_id 4024 ‚Üí 1555\n",
      "Updated 1 examples: query_id 4025 ‚Üí 1557\n",
      "Updated 1 examples: query_id 4048 ‚Üí 1569\n",
      "Updated 1 examples: query_id 4062 ‚Üí 1576\n",
      "Updated 1 examples: query_id 4132 ‚Üí 1613\n",
      "Updated 1 examples: query_id 4355 ‚Üí 1748\n",
      "Updated 2 examples: query_id 4483 ‚Üí 1821\n",
      "Updated 2 examples: query_id 4604 ‚Üí 1883\n",
      "\n",
      "‚úÖ Updated 28 example records\n",
      "üìã Ready to delete 25 duplicate queries\n"
     ]
    }
   ],
   "source": [
    "# Update example table using the mapping\n",
    "updates_made = 0\n",
    "with get_db_connection() as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        for old_id, new_id in id_mapping.items():\n",
    "            # Update examples that reference the duplicate query_id\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                UPDATE example \n",
    "                SET query_id = %s \n",
    "                WHERE query_id = %s\n",
    "            \"\"\",\n",
    "                (new_id, old_id),\n",
    "            )\n",
    "\n",
    "            updated_rows = cursor.rowcount\n",
    "            updates_made += updated_rows\n",
    "\n",
    "            if updated_rows > 0:\n",
    "                print(f\"Updated {updated_rows} examples: query_id {old_id} ‚Üí {new_id}\")\n",
    "\n",
    "        # Commit all updates\n",
    "        conn.commit()\n",
    "\n",
    "print(f\"\\n‚úÖ Updated {updates_made} example records\")\n",
    "print(f\"üìã Ready to delete {len(id_mapping)} duplicate queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è  Deleting duplicate queries from query table...\n",
      "Deleting 25 duplicate query records\n",
      "Sample IDs to delete: [2050, 2131, 2499, 2520, 2642, 2705, 2842, 2845, 2914, 2946, 2969, 4976, 3198, 3327, 3554, 3651, 3774, 4024, 4025, 4048, 4062, 4132, 4355, 4483, 4604]\n"
     ]
    }
   ],
   "source": [
    "# Delete duplicate queries from query table (keeping only first instance)\n",
    "print(\"üóëÔ∏è  Deleting duplicate queries from query table...\")\n",
    "\n",
    "duplicate_ids_to_delete = list(id_mapping.keys())\n",
    "print(f\"Deleting {len(duplicate_ids_to_delete)} duplicate query records\")\n",
    "print(f\"Sample IDs to delete: {duplicate_ids_to_delete}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted batch 1: 25 queries\n",
      "\n",
      "‚úÖ Successfully deleted 25 duplicate queries\n",
      "üéØ Kept 25 unique queries (first instances)\n"
     ]
    }
   ],
   "source": [
    "deleted_count = 0\n",
    "with get_db_connection() as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        # Delete duplicate queries in batches\n",
    "        batch_size = 100\n",
    "        for i in range(0, len(duplicate_ids_to_delete), batch_size):\n",
    "            batch = duplicate_ids_to_delete[i : i + batch_size]\n",
    "\n",
    "            # Create placeholders for the batch\n",
    "            placeholders = \",\".join([\"%s\"] * len(batch))\n",
    "\n",
    "            cursor.execute(\n",
    "                f\"\"\"\n",
    "                DELETE FROM query \n",
    "                WHERE id IN ({placeholders})\n",
    "            \"\"\",\n",
    "                batch,\n",
    "            )\n",
    "\n",
    "            batch_deleted = cursor.rowcount\n",
    "            deleted_count += batch_deleted\n",
    "            print(f\"Deleted batch {i // batch_size + 1}: {batch_deleted} queries\")\n",
    "\n",
    "        # Commit all deletions\n",
    "        conn.commit()\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully deleted {deleted_count} duplicate queries\")\n",
    "print(f\"üéØ Kept {len(duplicates_only)} unique queries (first instances)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verifying deduplication results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jk/dyw0vdnx2jg9lyq8m01n8nfm0000gn/T/ipykernel_80367/4240732941.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  updated_query_df = pd.read_sql(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Final Verification Results:\n",
      "=============================\n",
      "Total queries after deduplication: 4,932\n",
      "Unique queries after deduplication: 4,932\n",
      "Remaining duplicates: 0\n",
      "Orphaned examples: 0\n",
      "\n",
      "‚úÖ SUCCESS: Deduplication completed successfully!\n",
      "   - No duplicate queries remain\n",
      "   - No orphaned examples found\n",
      "   - Removed 25 duplicate records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jk/dyw0vdnx2jg9lyq8m01n8nfm0000gn/T/ipykernel_80367/4240732941.py:21: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  orphaned_examples = pd.read_sql(\"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Verify deduplication completed successfully\n",
    "print(\"üîç Verifying deduplication results...\")\n",
    "\n",
    "# Re-read query data to verify\n",
    "with get_db_connection() as conn:\n",
    "    # Get updated query counts\n",
    "    updated_query_df = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            id,\n",
    "            query_content,\n",
    "            created_at\n",
    "        FROM query\n",
    "        ORDER BY created_at DESC\n",
    "    \"\"\",\n",
    "        conn,\n",
    "    )\n",
    "\n",
    "    # Check for any remaining duplicates\n",
    "    remaining_duplicates = updated_query_df[\"query_content\"].value_counts()\n",
    "    remaining_duplicates = remaining_duplicates[remaining_duplicates > 1]\n",
    "\n",
    "    # Verify example table integrity\n",
    "    orphaned_examples = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT COUNT(*) as orphaned_count\n",
    "        FROM example e\n",
    "        LEFT JOIN query q ON e.query_id = q.id\n",
    "        WHERE q.id IS NULL\n",
    "    \"\"\",\n",
    "        conn,\n",
    "    )\n",
    "\n",
    "print(f\"\\nüìä Final Verification Results:\")\n",
    "print(f\"=============================\")\n",
    "print(f\"Total queries after deduplication: {len(updated_query_df):,}\")\n",
    "print(\n",
    "    f\"Unique queries after deduplication: {updated_query_df['query_content'].nunique():,}\"\n",
    ")\n",
    "print(f\"Remaining duplicates: {len(remaining_duplicates)}\")\n",
    "print(f\"Orphaned examples: {orphaned_examples.iloc[0]['orphaned_count']}\")\n",
    "\n",
    "if len(remaining_duplicates) == 0 and orphaned_examples.iloc[0][\"orphaned_count\"] == 0:\n",
    "    print(f\"\\n‚úÖ SUCCESS: Deduplication completed successfully!\")\n",
    "    print(f\"   - No duplicate queries remain\")\n",
    "    print(f\"   - No orphaned examples found\")\n",
    "    print(f\"   - Removed {total_records - len(updated_query_df)} duplicate records\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: Issues detected:\")\n",
    "    if len(remaining_duplicates) > 0:\n",
    "        print(f\"   - {len(remaining_duplicates)} queries still have duplicates\")\n",
    "    if orphaned_examples.iloc[0][\"orphaned_count\"] > 0:\n",
    "        print(\n",
    "            f\"   - {orphaned_examples.iloc[0]['orphaned_count']} orphaned examples found\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masala-embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
